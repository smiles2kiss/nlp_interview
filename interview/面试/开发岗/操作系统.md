1. 栈空间和堆空间清楚吗？不同空间里对象的生命周期有什么不同吗？  

   

2. 堆数据结构和栈数据结构知道吗？ 

   栈分配与堆分配

   * 栈分配算法简单高效，堆分配算法相对比较复杂
     * 如果在栈上分配小块内存，因为cache和内存映射已经建立，则效率会非常高，远远优于堆分配
     * 如果在栈上分配大块内存，在不考虑爆栈的情况下，cache命中和内存映射总是在有限的大小进行的，其在栈中分配的大块内存照样cache不命中，而且映射未建立，分配时间差不多。
   * **申请方式**：堆是由程序员自己申请并指明大小，栈由系统自动分配
   * **申请后响应**
     * 栈：**只要栈的剩余空间大于所申请空间**，系统将为程序提供内存，否则将报异常提示栈溢出
     * 堆：操作系统有一个**记录空闲内存地址的链表**，当系统收到程序的申请时，会**遍历该链表，寻找第一个空间大于所申请空间的堆结点**，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序
   * **申请大小的限制**
     * 栈是向低地址扩展的数据结      构，是一块连续的内存的区域。在WINDOWS下，栈的大小是2M（也有的说是1M，总之是      一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示overflow。
     * 堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。
   * **申请效率**
     * 栈由系统自动分配，速度较快。但程序员是无法控制的
     * 堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片
   * **分配和释放**
     * 堆在分配和释放时都要调用函数（MALLOC,FREE)
   * **访问时间**
     * 访问堆的一个具体单元，需要**两次访问内存**，第一次取得指针，第二次得到数据
     * 栈只需访问内存一次

 

3. 简述下逻辑地址空间、物理地址空间和虚拟地址空间

   (1) **逻辑地址空间：**

   * **逻辑地址**
     * 程序经过编译后，每个目标单元模块都是从0单元开始编址，即为逻辑地址
   * **逻辑地址空间**
     * 当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从0号单元开始编址的逻辑地址空间
     * 不同进程可以有相同的逻辑地址，因为这些相同的逻辑地址可以映射到主存的不同位置。

   (2) **物理地址空间**

   * **物理地址空间**
     * **内存中物理单元的集合**，它是地址转换的最终地址。
     * 进程在运行时**执行指令和访问数据都要通过物理地址**从主存中存取。

   (3) **地址重定位**

   * 当装入程序（Loader）将可执行代码装入内存时，必须**通过地址转换将逻辑地址转换成物理地址**，这个过程称为地址重定位

 

4. 操作系统分页管理和分段管理的机制？分页管理和分段管理有什么区别吗？

   (1) **内存的不连续分配**

   * 把程序分割成一块一块的装入内存，在物理上不用彼此相连，在逻辑上使用段表或者页表将离散分布的这些小块串起来形成逻辑上连续的程序。

   (2) **分页管理**

   * 把程序分成等长的小块。这些小块叫做“页（Page）”，内存也被分成和页面同样大小的”页框/页帧（Frame）“，一个页可以装到一个页框里
   * 在执行程序的时候根据一个页表去查找某个页面在内存的某个页框中，由此完成了逻辑到物理的映射
   * 存在内部碎片

   (3) **分段管理**    

   * 进程被分为很多的段，要装入一个进程，需要将进程所有的段装入主存中不一定连续的动态分区
   * 存在外部碎片

   (4) **区别**

   * 分页是为实现离散分配方式，以消减内存的外零头(外部碎片)，提高内存的利用率。段则是信息的逻辑单位，它含有一组其意义相对完整的信息
   * 页的大小固定且由系统决定；而段的长度却不固定，决定于用户所编写的程序
   * 分页的地址空间是一维的，程序员只需利用一个页地址，即可表示一个地址；而分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址

 

5. 进程和线程的区别是什么？进程和线程间通信的方式分别有哪些？你用过那几种？

   (1) **进程**

   * 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动
   * **进程是系统进行资源分配和调度的一个独立单位**

   (2) **线程**

   * 线程是进程的一个实体。
   * **线程**是CPU调度和分派的基本单位
   * 线程是比进程更小的能独立运行的基本单位
   * 线程自身不具有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)
   * 一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行.

   (3) **区别**：

   * 主要差别在于它们是不同的操作系统资源管理方式
   * 一个程序至少有一个进程，一个进程至少有一个线程。
   * **进程在执行过程中拥有独立的内存单元。而多个线程共享内存。**
   * **进程有独立的地址空间**，一个进程崩溃后，**在保护模式下不会对其它进程产生影响**，而线程只是一个进程中的不同执行路径。**
   * **线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间**，**一个线程死掉就等于整个进程死掉**，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。

   (4) **进程空间分布描述**：对于一个进程，其空间分布包括

   * **程序段(Text)**: 
     * 程序代码在内存中的映射，存放函数体的二进制代码
   * **初始化过的数据(Data)**:
     * 在程序运行初已经对变量进行初始化的数据
   * **未初始化过的数据(BSS)**:
     * 在程序运行初未对变量进行初始化的数据
   * **栈(Stack)**:
     * 存储局部、临时变量，函数调用时，存储函数的返回指针，用于控制函数的调用和返回
     * 在程序块开始时自动分配内存,结束时自动释放内存，其操作方式类似于数据结构中的栈
   * **堆(Heap)**:
     * 存储动态内存分配,需要程序员手工分配,手工释放.注意它与数据结构中的堆是两回事，分配方式类似于链表

    (5) **进程内存空间**

   * **栈**
     * 进程地址空间中最顶部的段是栈，用于存储函数参数和局部变量
     * 调用一个方法或函数会将一个新的栈帧（stack frame）压入到栈中，这个栈帧会在函数返回时被清理掉。
   * **内存映射段**
     * 内核将文件的内容直接映射到内存。内存映射是一种方便高效的文件I/O方式，所以被用来加载动态库。
   * **堆**
     * 堆用于运行时内存分配，堆用于存储那些生存期与函数调用无关的数据。
   * **BBS和数据段**
     * 在C语言中，BSS和数据段保存的都是静态（全局）变量的内容。区别在于BSS保存的是未被初始化的静态变量内容

 

6. 同步IO，异步IO了解吗？ 阻塞IO和非阻塞IO？

   (1) **同步IO**：

   * 同步IO指的是用户进程触发I/O操作并等待或者轮询的去查看I/O操作是否就绪
   * 同步IO的执行者是IO操作的发起者

   (2) **异步IO**

   * 异步IO是指用户进程触发I/O操作以后就立即返回，继续开始做自己的事情，而当I/O操作已经完成的时候会得到I/O完成的通知
   * 异步IO的执行者是内核线程，内核线程将数据从内核态拷贝到用户态

   (3) **区分阻塞IO和非阻塞IO**

   * 发起IO操作是否阻塞
   * 如果阻塞直到完成，就是阻塞IO，否则就是非阻塞IO

 

7. 了解select、poll和epoll的原理、区别吗？ 

   (1) **IO多路复用**

   * **内核一旦发现进程指定的**一个或者多个IO条件准备读取**，它就通知该进程

   (2) **出现情况**

   * 当客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用
   * 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现
   * 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用
   * 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用
   * 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用

   (3) **select**

   * 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds
   * 调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回
   * 当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。 

   (4) **Poll**

   * 本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态
   * 如果设备就绪则在设备等待队列中加入一项并继续遍历
   * 如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。
   * 这个过程经历了多次无谓的遍历

   (5) **Epoll**

   * 支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次
   * epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。



8. 进程有哪几种状态？操作系统中进程间的调度策略知道哪几种？ 
   * **运行状态：**进程正在处理器上上运行。在单处理器环境下，每个时刻最多只有一个进程处于运行状态
   * **就绪状态：**进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器即可运行
   * **阻塞状态：**又称为等待状态，进程**正在等待某一事件而暂停运行**，如等待某资源为可用（不包括处理器）或等待输入/输出完成。即使处理器空闲，该进程也不能运行
   * **创建状态：**进程正在被创建，尚未到就绪状态
   * **结束状态：**进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行

 

9. **调度算法**

   (1) **先来先服务调度算法**

   * 当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列
   * **在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。**

   (2) **短作业(进程)优先调度算法**

   * 短作业(进程)优先调度算法SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。
   * 短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。
   * **短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。**

   (3) **高优先权优先调度算法**

   * **非抢占式优先权算法**
     * 系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程
     * **主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中**
   * **抢占式优先权调度算法**
     * 系统把处理机分配给优先权最高的进程，使之执行
     * 但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。
     * **常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。**

 

9. 内存分页管理的页面置换策略有哪些？ 

   (1) **FIFO页置换**

   * 最简单的页置换算法。选择**最旧的页**进行置换
   * **Belady现象**：在采用FIFO算法时，有时会出现分配的物理页面数增加，缺页率反而提高的异常现象

   (2) **最优置换**

   * 置换最长时间不使用的页（预测其未来经过多长时间才被使用，淘汰最长时间未使用的页面）

   (3) **LRU页置换（最近最少使用算法）**

   * 依据: 页将来使用的时间
   * 淘汰: 近期最少使用的算法(即当缓存满时，淘汰最长时间未使用的页面)
   * **LRUcache**的缓存算法
     * **使用场景**: CPU的高速缓存机制
     * **目标**：删除CPU中很长时间未使用的数据
     * **涉及的数据结构**: 字典(哈希表) + 双向链表
     * **过程**: 
       * 双向链表用于记录元素被塞进cache的顺序，用于淘汰最久未被使用的元素
       * 哈希表用于直接记录元素的位置，即利用O(1)的时间复杂度来拿到链表的元素
     * **get操作的逻辑**：
       * 根据传入的key取哈希表里拿到对应的元素。如果该元素存在，就把该元素挪到链表的尾部。
     * **put操作的逻辑**：
       * 首先判断key是否在哈希表中，如果在的话就更新值，并把元素挪到链表的尾部。
       * 如果key未在哈希表中，则说明是一个新的元素，此时需要判断cache的容量。
       * 如果超过了cache的容量，则需要淘汰链表的头部，在将新的元素插入到链表尾部。
       * 如果未超过最大容量，则直接在链表尾部追加新的元素。

   (4) **时钟页面置换算法**

   (5) **近似LRU页置换**

   (6) **基于计数的页置换**：为每个页设置一个计数器

   (7) **最不经常使用页置换算法（LFU)**

   (8) **置换计数最小页**

   (9) **最常使用页置换算法（MFU)**

   (10) **置换计数最大页**

   (11) **抖动问题**：

   * 如果分配给一个进程的物理页面太少，不能包含整个的工作集，即常驻集包含于工作集，那么进程将会造成很多的缺页中断，需要频繁地在内存与外存之间替换页面，从而使进程的运行速度变得很慢，把这种状态称为“抖动”。

 

10. 介绍一下操作系统中断的过程？中断发生时，内存中数据怎么存储的，存到哪？怎么恢复？ 

    (1) **目的**：请求硬件设备

    * 中断是系统响应硬件设备请求的一种机制，它会打断进程的正常调度和执行，然后调用内核中的中断处理程序来响应设备的请求
    * 要求中断程序要及时响应中断，然后迅速处理，以便等待下次中断到来。如果处理得比较慢，有可能会错过下次中断的响应，导致数据丢失等问题。

    (2) **内存数据存储**

    * **请求中断**
      * 当某一中断源需要CPU为其进行中断服务时，就输出中断请求信号，使中断控制系统的中断请求触发器置位，向CPU请求中断。系统要求中断请求信号一直保持到CPU对其进行中断响应为止。

    * **中断响应**
      * CPU对系统内部中断源提出的中断请求必须响应，而且自动取得中断服务子程序的入口地址，执行中断 服务子程序
      * 对于外部中断，CPU在执行当前指令的最后一个时钟周期去查询INTR引脚
      * 若查询到中断请求信号有效，同时在系统开中断（即IF=1）的情 况下，CPU向发出中断请求的外设回送一个低电平有效的中断应答信号，作为对中断请求INTR的应答，系统自动进入中断响应周期。

    * **关闭中断**
      * CPU响应中断后，输出中断响应信号，自动将状态标志寄存器FR或EFR的内容压入堆栈保护起来，然后将FR或EFR中的中断标志位IF与陷阱标志位TF清零，从而自动关闭外部硬件中断
      * 因为CPU刚进入中断时要保护现场，主要涉及堆栈操作，此时不能再响应中断，否则将造成系统混乱
    * **保护断点**
      * 保护断点就是将CS和IP/EIP的当前内容压入堆栈保存，以便中断处理完毕后能返回被中断的原程序继续执行，这一过程也是由CPU自动完成。
    * **中断源识别**
      * 当系统中有多个中断源时，一旦有中断请求，CPU必须确定是哪一个中断源提出的中断请求，并由中断控制器给出中断服务子程序的入口地址，装入CS与IP/EIP两个寄存器
      * CPU转入相应的中断服务子程序开始执行
    * **保护现场**
      * 主程序和中断服务子程序都要使用CPU内部寄存器等资源，为使中断处理程序不破坏主程序中寄存器的内容，应先将断点处各寄存器的内容压入堆栈保护起来，再进入的中断处理
      * 现场保护是由用户使用PUSH指令来实现的。
    * **中断服务**
      * 中断服务是执行中断的主体部分，不同的中断请求，有各自不同的中断服务内容，需要根据中断源所要完成的功能，事先编写相应的中断服务子程序存入内存，等待中断请求响应后调用执行。
    * **恢复现场**
      * 当中断处理完毕后，用户通过POP指令将保存在堆栈中的各个寄存器的内容弹出，即恢复主程序断点处寄存器的原值。
    * **中断返回**
      * 在中断服务子程序的最后要安排一条中断返回指令IRET，执行该指令，系统自动将堆栈内保存的 IP/EIP和CS值弹出，从而恢复主程序断点处的地址值，同时还自动恢复标志寄存器FR或EFR的内容，使CPU转到被中断的程序中继续执行。

 

11. 简述一下用户态和内核态。什么情况下，会发生用户态到内核态的切换

    为了限制不同程序之间的访问能力，防止他们获取别的程序的内存数据。

    (1) **内核态**

    * CPU可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。

    (2) **用户态**

    * 只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。

    (3) **用户态和内核态的切换**

    * 所有用户程序都是运行在用户态的，但如果程序需要从硬盘读取数据，或者从键盘获取输入，则需要请求操作系统以系统调用的方式完成相应的操作。
    * 系统调用是由操作系统实现提供的所有系统调用所构成的集合即程序接口或应用编程接口。
    * 3种方式:
      * **系统调用**
        * 用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。
      * **异常**
        * 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中
      * **外围设备的中断**
        * 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序
        * 如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。

 

12. 进程和线程的区别

    (1) **地址空间和其它资源**

    * 进程间拥有独立内存，进程是资源分配的最小单位；
    * 线程隶属于某一个进程，且同一进程的各线程间共享内存(资源)，线程是CPU调度的最小单位。

    (2) **通信**

    * 进程间相互独立，通信困难，常用的方法有: **信号量，管道，套接字，共享内存，消息队列**等。
    * 线程间可以直接读写进程数据段(全局变量)来进行通信---需要进程同步和互斥手段的辅助，以保持数据的一致性

    (3) **调度和切换**

    * 线程上下文切换比进程上下文切换要快。进程间切换要保护上下文，加载另一个进程；
    * 线程则共享了进程的上下文环境，切换更快。

 

13. 什么是死锁，死锁发生的必要条件，解决死锁的基本方法有哪些

    (1) **定义**

    死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。

    (2) **死锁的必要条件**

    * **互斥条件**
      * 进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。
    * **请求和保持条件**
      * 进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。

    * **不剥夺条件**
      * 进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。

    * **环路等待条件**
      * 在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。

 

14. 线程之间如何通信？线程之间如何资源共享？

    (1) **定义**: 通信目的主要是用于线程同步。

    (2) **锁机制**

    * **互斥锁**
      * 确保同一时间只能有一个线程访问共享资源
      * 当锁被占用时试图对其加锁的线程都进入阻塞状态(释放CPU资源使其由运行状态进入等待状态)
      * 当锁释放时哪个等待线程能获得该锁取决于内核的调度
    * **读写锁**
      * 当以写模式加锁而处于写状态时任何试图加锁的线程(不论是读或写)都阻塞
      * 当以读状态模式加锁而处于读状态时“读”线程不阻塞，“写”线程阻塞
      * 读模式共享，写模式互斥。 

    * **条件变量**
      * 可以以原子的方式阻塞进程，直到某个特定条件为真为止
      * 对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
    * **自旋锁**
      * 上锁受阻时线程不阻塞而是在循环中轮询查看能否获得该锁，没有线程的切换因而没有切换开销，不过对CPU的霸占会导致CPU资源的浪费
      * 自旋锁适用于并行结构(多个处理器)或者适用于锁被持有时间短而不希望在线程切换产生开销的情况。

    (3) **信号量机制**

    * 信号量实际上是一个非负的整数计数器，用来实现对公共资源的控制
    * 在公共资源增加的时候，信号量就增加；公共资源减少的时候，信号量就减少
    * 只有当信号量的值大于0的时候，才能访问信号量所代表的公共资源。

    (4) **信号机制**

    (5) **violate全局变量共享内存**

    (6) **wait/notify阻塞/唤醒**