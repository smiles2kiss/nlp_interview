1. 归一化和标准化的区别

2. BN为什么能够加速收敛

   (1) BN作用

   ​	加速收敛，提高泛化能力，防止过拟合

   (2) BN目的

   ​	解决internal covariate shift问题呢？简单的说就是后一层要去处理前一层给的数据，而由于前一层的参数变化，后一层的输入分布会跟着变化，后一层的训练也要跟着分布的变化而变化。

   ​	在训练时，是对每一批的训练数据进行归一化，也即用每一批数据的均值和方差。

   ​	在测试时，比如进行一个样本的预测，就并没有batch的概念，因此，这个时候用的均值和方差是全量训练数据的均值和方差，这个可以通过移动平均法求得。

 

3. BN为什么需要还原

4. BN为啥可以缓解过拟合，详细讲一下 ，BN有哪些需要学习的参数啊，BN训练和测试是怎么做的？

5. BN一般用在网络的那个部分呢

6. 存在哪些加速收敛的方法，BN, GN, IN, FN的原理详细解释一下呢

   深度学习中的 Internal Covariate Shift 问题及其影响

   (1) 独立同分布 (iid)

   * 朴素贝叶斯分类器：以假设特征之间强（朴素）独立下运用贝叶斯定理为基础的简单概率分类器。
   * 神经网络不要求

   (2) 白化 (数据预处理)

   * 去除特征之间的相关性 -> 独立
   * 使得所有特征具有相同的均值和方差 -> 同分布

 

7. Normalization常用方法
   * Batch Normalization
   * Layer Normalization
   * Weight Normalization
   * Cosine Normalization