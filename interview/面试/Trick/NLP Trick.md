1. 在文本分类任务中，如何处理类别不平衡的问题? 正负样本不均衡的问题，如何解决？一种可行的方案是用拒绝推断，一种方案是用smote？

  ​	假设多分类任务中，其中一个类别A的样本数为50000， 另一个类别B的样本数为100。
  ​	简单通用的方法

  * 对较多的那个类别进行欠采样(under-sampling)，舍弃一部分数据，使其与较少类别的数据相当
  * 对较少的类别进行过采样(over-sampling)，重复使用一部分数据，使其与较多类别的数据相当
    常用算法：SMOTE是一种过采样算法，它构造新的小类样本而不是产生小类中已有的样本的副本，即该算法构造的数据是新样本，原数据集中不存在的。
  * 阈值调整（threshold moving），将原本默认为0.5的阈值调整到较少类别/（较少类别+较多类别）即可



2. 自然语言处理中，有哪些数据增强的方法
	* 同义词替换 (SR: Synonyms Replace)
	  * 不考虑stopwords，在句子中随机抽取n个词，然后从同义词词典中随机抽取同义词，并进行替换。
	* 随机插入 (RI: Randomly Insert)
	  * 不考虑stopwords，随机抽取一个词，然后在该词的同义词集合中随机选择一个，插入原句子中的随机位置。该过程可以重复n次。
	* 随机交换 (RS: Randomly Swap)
	  * 句子中，随机选择两个词，位置交换。该过程可以重复n次
	* 随机删除 (RD: Randomly Delete)
	  * 句子中的每个词，以概率p随机删除。
	
3. 细粒度的任务如何解决？

4. 文本分类中的多义词问题可以怎么解决？

5. 文本生成中的搜索算法
* beam/greedy search 原理？
* beam search的优化，除以长度平均每个词的概率，diverse beam_search啥的？
* beam search，如何在做生成任务的时候，生成多个结果并且保证结果的多样性？
* beam search中的eos token之后如何处理